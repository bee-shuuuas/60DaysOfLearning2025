# Day 4

Today is the fourth day of my 60 days learning Data Science, AI/ML journey and here today I did another project of Dog_Breed_Prediction and while doing this project, I go to known about Convolution layer and pooling layer.

## üìù **Day 4 Summary ‚Äì Dog Breed Classifier with CNN**

Today was **Day 4** of my 60-day learning journey, and I worked on building a **Dog Breed Classifier** using **Keras and TensorFlow**. It was an exciting day because I applied what I learned about **convolution** and **pooling** in a real project!

---

### üß† **What I Did:**

In this project, I used **Keras** and **TensorFlow** to create a **Convolutional Neural Network (CNN)** that could identify the breed of a dog in an image. This is a **supervised learning problem** (which means I used labeled data for training), specifically a **multiclass classification problem** (because there are multiple dog breeds to predict).

I built the CNN model from scratch and trained it on a dataset of dog images to predict the breed. The project focused a lot on **image classification**, and it was a cool introduction to deep learning with real-world data.

---

### üßë‚Äçüíª **What I Practiced:**

Aside from the project, I also spent time understanding the core concepts of **convolution** and **pooling** in Python:

* **Convolution**: This is where the CNN applies filters (kernels) to the image to extract important features like edges, textures, or shapes. I practiced how these filters "slide" over the image and help the network identify what‚Äôs important. I now understand how **convolution layers** in CNNs are key to detecting features.
  
* **Pooling**: Pooling helped me reduce the size of the feature maps, which made the model faster and more efficient. **Max pooling** picks out the most important parts of the image, essentially making the model focus on the most significant features without worrying about small details. This also helps prevent overfitting.

---

### ü§î **Why Not Send Images Directly to the Model?**

One of the big questions I had was: **Why don't we just send raw images to the model?**

Here‚Äôs why:

* Raw images are often very large (in terms of pixel values), and feeding them directly into the model can lead to inefficiency and slow processing.
  
* **Convolution** and **pooling** help the model focus on the **relevant features** (edges, shapes, etc.), making it easier and faster to learn from the image.
  
* These steps also help reduce the **dimensionality** of the image data, making the training process more efficient without losing critical information.

---

