## 📅 Day 7 — Tensor Operations & Autograd

Today, I explored the powerful and essential **Tensor** data structure, which is the backbone of most deep learning frameworks.

### 🔍 What I Learned:
- 🔢 **Tensor Arithmetic Operations**: Performed element-wise operations like addition, subtraction, multiplication, and division.
- 🔄 **Tensor Manipulations**: Explored reshaping, slicing, and broadcasting techniques.
- 🧠 **Autograd in PyTorch**:
  - Understood how `requires_grad` enables automatic differentiation.
  - Used `.backward()` to compute gradients.
  - Learned how to **detach** gradients when needed to prevent tracking in computation graphs.

### 📌 Key Takeaway:
Autograd is a powerful tool in PyTorch that automates the computation of gradients — crucial for backpropagation in neural networks. It significantly simplifies the process of training models.

### 📁 Resources:
All related PDFs and hands-on activities for Day 7 are available in this directory:
